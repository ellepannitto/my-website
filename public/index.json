[{"authors":["admin"],"categories":null,"content":"I am a second year PhD student at the Center for Mind/Brain Sciences (CIMeC) at University of Trento, under the supervision of Aurélie Herbelot. My research fields are Computational Semantics and Natural Language Processing.\nEverything in life is a work-in-progress, this place especially.\n","date":1563302267,"expirydate":-62135596800,"kind":"taxonomy","lang":"en","lastmod":1563302267,"objectID":"2525497d367e79493fd32b198b28f040","permalink":"https://ellepannitto.github.io/authors/admin/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/authors/admin/","section":"authors","summary":"I am a second year PhD student at the Center for Mind/Brain Sciences (CIMeC) at University of Trento, under the supervision of Aurélie Herbelot. My research fields are Computational Semantics and Natural Language Processing.\nEverything in life is a work-in-progress, this place especially.","tags":null,"title":"Ludovica Pannitto","type":"authors"},{"authors":["Emmanuele Chersoni","Enrico Santus","Ludovica Pannitto","Alessandro Lenci","Philippe Blache","Chu-Ren Huang"],"categories":[],"content":"","date":1563302267,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1563302267,"objectID":"72a107e01c127d4b3f8eb483d9b51833","permalink":"https://ellepannitto.github.io/publication/structured/","publishdate":"2019-07-16T20:37:47+02:00","relpermalink":"/publication/structured/","section":"publication","summary":"Most compositional distributional semantic models represent sentence meaning with a single vector. In this paper, we propose a structured distributional model (SDM) that combines word embeddings with formal semantics and is based on the assumption that sentences represent events and situations. The semantic representation of a sentence is a formal structure derived from discourse representation theory and containing distributional vectors. This structure is dynamically and incrementally built by integrating knowledge about events and their typical participants, as they are activated by lexical items. Event knowledge is modelled as a graph extracted from parsed corpora and encoding roles and relationships between participants that are represented as distributional vectors. SDM is grounded on extensive psycholinguistic research showing that generalized knowledge about events stored in semantic memory plays a key role in sentence comprehension. We evaluate SDM on two recently introduced compositionality data sets, and our results show that combining a simple compositional model with event knowledge constantly improves performances, even with dif ferent types of word embeddings.","tags":[],"title":"A structured distributional model of sentence meaning and processing","type":"publication"},{"authors":["Ludovica Pannitto","Alessandro Lenci"],"categories":[],"content":"","date":1544985467,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1544985467,"objectID":"02a2e1f1143b05230ad1056e0a3e7df3","permalink":"https://ellepannitto.github.io/publication/medea/","publishdate":"2018-12-16T20:37:47+02:00","relpermalink":"/publication/medea/","section":"publication","summary":"The great majority of compositional  models  in  distributional  semantics present methods to compose distributional vectors or tensors in a representation of the sentence.   Here we propose to enrich the best performing method (vector addition, which we take as a baseline) with distributional knowledge about events, outperforming our baseline.","tags":[],"title":"MEDEA: Merging Event knowledge and Distributional vEctor Addition","type":"publication"},{"authors":["Lucia Busso","Ludovica Pannitto","Alessandro Lenci"],"categories":[],"content":"","date":1544985467,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1544985467,"objectID":"258c9911c8130432123d232f4d174e23","permalink":"https://ellepannitto.github.io/publication/modeling/","publishdate":"2018-12-16T20:37:47+02:00","relpermalink":"/publication/modeling/","section":"publication","summary":"The present study combines psycholinguistic evidence on Italian valency coercion and a distributional analysis. The paper suggests that distributional properties can provide useful insights on how general abstract constructions influence the resolution of coercion effects. However, complete understanding of the processing and recognition of coercion requires to take into consideration the complex intertwining of lexical verb and abstract constructions.","tags":[],"title":"Modelling Italian construction flexibility with distributional semantics: Are constructions enough?","type":"publication"},{"authors":["Ludovica Pannitto","Lavinia Salicchi","Alessandro Lenci"],"categories":[],"content":"","date":1544985467,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1544985467,"objectID":"9a8f2cb731c219b8a16535c6856ea053","permalink":"https://ellepannitto.github.io/publication/refining/","publishdate":"2018-12-16T20:37:47+02:00","relpermalink":"/publication/refining/","section":"publication","summary":"Several unsupervised methods for hypernym detection have been investigated in distributional semantics. Here we present a new approach based on a smoothed version of the distributional inclusion hypothesis. The new method is able to improve hypernym detection after testing on the BLESS dataset.","tags":[],"title":"Refining the Distributional Inclusion Hypothesis for Unsupervised Hypernym Identification","type":"publication"},{"authors":["Ludovica Pannitto"],"categories":[],"content":"","date":1539715067,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1539715067,"objectID":"2f9647fce8b4ff402b628539d2b138dd","permalink":"https://ellepannitto.github.io/publication/event/","publishdate":"2018-10-16T20:37:47+02:00","relpermalink":"/publication/event/","section":"publication","summary":"","tags":[],"title":"Event Knowledge in Compositional Distributional Semantics","type":"publication"},{"authors":["Ludovica Pannitto","Lavinia Salicchi","Alessandro Lenci"],"categories":[],"content":"","date":1502908667,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1502908667,"objectID":"7e79362a74d8d287fa4058492ae8bd28","permalink":"https://ellepannitto.github.io/publication/ahyda/","publishdate":"2017-08-16T20:37:47+02:00","relpermalink":"/publication/ahyda/","section":"publication","summary":"Several unsupervised methods for hypernym detection have been investigated in distributional semantics.  Here we present a new approach based on a smoothed version of the distributional inclusion hypothesis.  The new method is able to improve hypernym detection after testing on the BLESS dataset.","tags":[],"title":"AHyDA: Automatic Hypernym Detection with feature Augmentation","type":"publication"},{"authors":["Giuseppe Attardi","Antonio Carta","Federico Errica","Andrea Madotto","Ludovica Pannitto"],"categories":[],"content":"","date":1502908667,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1502908667,"objectID":"d2ab79f628dfc23f460bc923d03b613f","permalink":"https://ellepannitto.github.io/publication/fa3l/","publishdate":"2017-08-16T20:37:47+02:00","relpermalink":"/publication/fa3l/","section":"publication","summary":"In this paper we present ThReeNN, a model for Community Question Answering, Task 3, of SemEval-2017. The proposed model exploits both syntactic and semantic information to build a single and meaningful embedding space. Using a dependency parser in combination with word embeddings, the model creates sequences of inputs for a Recurrent Neural Network, which are then used for the ranking purposes of the Task. The score obtained on the official test data shows promising results.","tags":[],"title":"FA3L at SemEval-2017 Task 3: A ThRee Embeddings Recurrent Neural Network for Question Answering","type":"publication"}]